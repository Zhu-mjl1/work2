## 7.29讲座内容总结

### 提要

讲座中，教授详细探讨了自监督学习与知识蒸馏的关键概念和应用。

讲座首先介绍了泛化误差界（Generalisation Error Bound），讨论了模型在训练集和测试集上的表现差距，并详细解释了相关参数的影响。接着，教授介绍了在面部图像标记任务中使用KL散度处理非高斯误差概率分布的问题，并引入了校正翼损失函数（Rectified Wing Loss）来提高性能。此外，还讨论了损失函数的计算和应用策略，以及异常检测中分类器不一致性的问题，强调了泛化误差和未来性能评估的重要性。

随后，教授分析了传统监督学习（Supervised Learning）的局限性，特别是数据标注成本高、不可扩展、信息含量低等问题，指出这些模型并不是解决所有问题的灵丹妙药（not a panacea）。在过渡到自监督学习（Self-Supervised Learning, SSL）之前，教授介绍了SSL的关键成分，包括未标注训练集、前文本任务、数据增强和辅助网络架构等。最后，讲座涵盖了当前自监督学习领域的研究热点，如知识蒸馏中的教师和学生网络参数更新、监督信号的更新方法，以及SSL中的各种优化技术。

### 1. 损失函数的计算与应用

**KL散度（Kullback-Leibler Divergence）**：
- 用于衡量两个概率分布之间的差异。
- 在机器学习中，KL散度常用于优化模型，使预测分布尽可能接近真实分布。
- 公式：$$ D_{KL}(P \| Q) = \sum_i P(i) \log \frac{P(i)}{Q(i)} $$
- 问题：如果预测概率非常接近零，KL散度值会趋向无穷大，导致数值不稳定。

**交叉熵（Cross Entropy）**：
- 常用于分类任务的损失函数。
- 通过最小化交叉熵损失，使模型的预测概率分布接近真实的类别分布。
- 公式：$$ H(P, Q) = -\sum_i P(i) \log Q(i) $$
- 特点：在训练的早期阶段，交叉熵损失主导优化过程，帮助模型快速提高分类准确性。

### 2. 正则化方法

**2016年方法**：
- 基于高斯类别条件概率密度和中心损失函数（Wen2016）。
- 通过引入类别条件熵和无条件熵的约束，增强模型的鲁棒性和泛化能力。
- 公式：
  $$ 
  J(\mathcal{V}, W, z) = \mathbb{E}_{z \in \mathcal{Z}} \{ \log P(y|z(x)) \} + \frac{1}{m} \sum_{i} \mathbb{E}_{z \in \mathcal{Z}_i} \{ \log Q(z|y) \} - \mathbb{E}_{z \in \mathcal{Z}} \{ \log Q(z) \}
  $$
  - $\mathcal{Z}$：嵌入空间中的训练样本集
  - $P(y|z(x))$：类别概率的预测值
  - $Q(z|y)$：在给定类别 $y$ 的条件下，潜在表示 $z$ 的概率

**2022年方法**：
- 熵正则化散度（Entropy Regularized Divergence），结合交叉熵和最近代理三重态损失（NPT Loss）。
- 通过最大化同类样本相似度并最小化异类样本相似度，优化特征空间中的样本分布。
- 公式：
  $$ 
  J = \frac{1}{N} \left\{ \sum_j \log P(y_j|z_j) + \lambda [\hat{z}_j^T \mu_{y_j} - \hat{z}_j^T \mu_{i^*}] \right\}
  $$
  - $\hat{z}_j$：样本 $j$ 在特征空间中的表示
  - $\mu_{y_j}$：类别 $y_j$ 的中心向量
  - $\mu_{i^*}$：样本 $j$ 距离最远的非类别 $y_j$ 的中心向量
  - $\lambda$：正则化项的权重参数

### 3. 异常检测中的分类器不一致性

**分类器不一致性**：
- 当不同分类器或模式（如多模态生物识别或多摄像头视角）在同一任务上给出不一致的结果时，可以用来标记异常。
- 例如：面部识别和指纹识别结果不一致可能表明存在异常。

**应用场景**：
- **多模态生物识别**：面部识别与指纹识别的结果不一致，可能需要进一步验证。
- **多摄像头视角**：不同摄像头视角下的行为模式不一致，可以标记为异常。
- **上下文决策**：通过上下文信息判断行为是否异常，如厨房中异常的行为模式。

**关键假设**：
- **主导类**：主要关注大多数情况下占主导地位的类。
- **非主导类的联合**：联合考虑单独情况下不常见但联合起来可能表明异常的类。

**决策认知的KL散度**：
- 通过KL散度量化分类器之间的决策差异，从而识别异常。

### 4. 泛化误差和未来性能评估

**泛化误差界（Generalization Error Bound）**：
- 泛化误差由训练集误差和附加误差项组成。
- 公式：
  $$ 
  \mathcal{R}_{gen} \leq \mathcal{R}_{emp} + f(\gamma, \lambda, T, N, L_{max}, \delta, n_W)
  $$
  - $\mathcal{R}_{gen}$：泛化误差
  - $\mathcal{R}_{emp}$：训练集误差
  - $f(\gamma, \lambda, T, N, L_{max}, \delta, n_W)$：附加误差项，影响因素包括：
    - $\gamma$：Lipschitz常数
    - $\lambda$：学习率
    - $T$：迭代次数
    - $N$：训练样本数量
    - $L_{max}$：损失函数最大值
    - $\delta$：界限为真的概率
    - $n_W$：模型参数数量

**KL散度的问题**：
- 使用KL散度时，损失函数可能趋向无穷大，需注意数值稳定性问题。

### 5. 自监督学习的关键成分（Key Ingredients of SSL）

#### 内容
教授介绍了自监督学习（Self-Supervised Learning, SSL）的关键成分，这些成分是构建和训练有效自监督学习模型的基础。

- **未标注的训练集（Unlabeled Training Set）**：自监督学习依赖大量未标注的数据集，这些数据集比标注数据集更容易获取和扩展。
  
- **前文本（辅助）任务（Pre-text (Auxiliary) Tasks）**：
  - **旋转（Rotation）**：要求模型预测图像的旋转角度。
  - **重建（Reconstruction）**：要求模型从部分遮盖或噪声污染的输入中重建原始图像。
  - **并置（Juxtaposition）**：预测两个图像块是否相邻。
  - **遮掩（Masking）**：预测被遮盖区域的内容。

- **数据增强（Data Augmentation）**：通过对训练数据进行各种变换（如旋转、缩放、翻转）来生成更多的训练样本，提高模型的鲁棒性和泛化能力。

- **辅助网络架构（Auxiliary Network Architecture）**：
  - **连体网络（Siamese Twin）**：两个共享权重的子网络，通过比较输入对的相似性进行训练。

- **训练策略（Training Strategy）**：包括如何组织和调度训练过程，使得模型能够有效地从辅助任务中学习。

- **损失函数（Loss Functions）**：定义模型的学习目标，通过最小化损失函数来优化模型。
  
- **优化程序（Optimization Procedures）**：定义如何更新模型的参数，使得模型能够收敛到最优解。

### 6. 自监督学习的信息论公式（Information Theoretic Formulation of SSL）

#### 内容
教授详细介绍了自监督学习的核心学习目标，使用Kullback-Leibler散度（KL散度）公式来量化分布之间的差异。

- **公式**：
  $$
  J_{KL}(Q||P) = \int Q(y, z) \log \frac{Q(y|z)}{P(y|z, W)} = \int Q(y, z) \log Q(y|z) - \int Q(y, z) \log P(y|z, W)
  $$

#### 解释
- **训练集**：使用未标注的数据集进行训练。
- **目标**：将训练数据聚类到嵌入空间中，使得相似的样本具有相似的嵌入表示。
- **网络架构**：核心网络架构由骨干权重$\theta$和预测器权重$w_i$参数化。
- **计算**：对于每个训练点，骨干网络计算嵌入$Z$和聚类概率$P(i|z, w_i)$。

### 7. 学习目标和优化（Objective Function and Optimization）

#### 内容
教授进一步介绍了自监督学习中的目标函数和优化过程，特别是如何通过正则化项来避免退化解。

- **公式**：
  $$
  \mathcal{L}(Q||P) = \int Q(y, z) \log Q(y|z) - \sum_{i=1}^k \int_z Q(i, z) \log P(i|z, W) + \sum_{i=1}^k \int_z Q(i, z) \log \int_z Q(i, z)
  $$

- **解释**：
  - 第一个项：表示条件分布$Q(y|z)$的信息熵。
  - 第二个项：表示聚类概率$P(i|z, W)$的信息熵。
  - 第三个项：表示类别$i$的先验概率分布$Q(i, z)$的信息熵。

### 8. 研究现状（Current Research in SSL）

#### 内容
教授总结了当前自监督学习领域的一些研究热点和方向，包括：

- **蒸馏（Distillation）**
- **不对称性（Asymmetry）**
  - **架构（Architectural）**：如投影器、预测器的设计。
  - **架构参数（Architecture Parameters）**：如动量更新。
  - **方差（Variance）**
  - **批归一化（Batch Normalization）**
  - **温度差异（Temperature Difference）**
  
- **SSL的原理（Principle of SSL）**：包括聚类、Barlow的冗余减少、信息瓶颈等。
- **架构（Architecture）**
- **批大小和归一化（Batch Size and Normalization）**
- **数据增强方法/遮掩（Augmentation Methods/Masking）**
- **损失函数（Loss Functions）**：定义、位置、方式。
- **正样本与负样本学习（Positive Sample Only vs. Positive/Negative Sample Learning）**

### 9. 知识蒸馏（Distillation）

#### 内容

#### 教师网络参数更新（Teacher Network Parameter Update）

教授介绍了在知识蒸馏过程中，教师网络的参数更新方法，主要通过指数移动平均（EMA）进行更新：

$$
\theta_T^{\text{new}} = \alpha \theta_T + (1 - \alpha) \theta_S
$$

$$
W_T^{\text{new}} = \alpha W_T + (1 - \alpha) W_S
$$

- **解释**：教师网络的参数通过指数移动平均从学生网络的参数中更新，以确保教师网络逐渐吸收学生网络的知识。这里，$\alpha$ 是动量系数，介于0和1之间。

#### 学生网络参数更新（Student Network Parameter Update）

教授还介绍了学生网络的参数更新方法，通过最小化与教师网络的软目标和硬目标之间的损失来实现：

- **软目标损失（Soft Target Loss）**：
  $$
  L_{\text{soft}} = \sum_{i} p_i^{\text{teacher}} \log(p_i^{\text{student}})
  $$

- **硬目标损失（Hard Target Loss）**：
  $$
  L_{\text{hard}} = \sum_{i} y_i \log(p_i^{\text{student}})
  $$

- **总损失**：
  $$
  L_{\text{total}} = \alpha L_{\text{hard}} + (1 - \alpha) L_{\text{soft}}
  $$

- **解释**：通过结合软目标损失和硬目标损失，学生网络能够学习到教师网络的知识，同时保持对标注数据的准确性。$\alpha$ 是权重系数，用于平衡软目标和硬目标的损失。

#### 监督信号更新（Supervisory Signal Update）

教授还介绍了如何更新监督信号，包括先验概率和后验概率的计算：

- **先验概率（Prior）**：
  $$
  Q(y) = \int_z P(y|z, W)|_{\theta_T, W_T}
  $$

- **后验概率（Posterior）**：
  $$
  Q(y|z) = \frac{P(y|z, W)|_{\theta_T, W_T}}{Q(y)}
  $$

- **解释**：先验概率$Q(y)$是通过积分计算的，即在给定教师网络参数$\theta_T$和$W_T$的情况下，计算$P(y|z, W)$的积分。后验概率$Q(y|z)$则是通过将条件概率$P(y|z, W)$除以先验概率$Q(y)$来计算的。



