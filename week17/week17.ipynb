{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a6ef29",
   "metadata": {},
   "source": [
    "# WEEK 17\n",
    "\n",
    "2024/07/29 - 2024/08/04\n",
    "\n",
    "## 深度学习 C5_W3\n",
    "\n",
    "### 1. 不同的语言翻译算法\n",
    "\n",
    "- **神经机器翻译（Neural Machine Translation, NMT）**：\n",
    "  - 基于神经网络的机器翻译方法，使用编码器-解码器结构进行序列到序列的转换。\n",
    "  - 编码器将输入序列编码成一个固定长度的上下文向量，解码器根据该上下文向量生成目标序列。\n",
    "  - 常见模型包括LSTM、GRU和Transformer。\n",
    "\n",
    "- **基于规则的机器翻译**：\n",
    "  - 使用语言学规则和词典进行翻译，依赖人工编写的规则。\n",
    "  - 优点是易于理解和控制，缺点是扩展性差。\n",
    "\n",
    "- **基于统计的机器翻译（Statistical Machine Translation, SMT）**：\n",
    "  - 通过统计模型和大规模双语语料库进行翻译。\n",
    "  - 使用概率模型，如最大熵模型和隐马尔可夫模型。\n",
    "  - 计算句子中单词或短语的联合概率，选择概率最大的翻译。\n",
    "\n",
    "### 2. 优化光束搜索并分析错误\n",
    "\n",
    "- **光束搜索（Beam Search）**：\n",
    "  - 是一种用于解码序列模型的搜索算法，通过保留固定数量的最优候选序列来找到最优翻译。\n",
    "  - 优化光束搜索的方法包括调整光束宽度和结合其他搜索策略。\n",
    "  - 光束宽度决定了每一步保留的候选序列数，宽度越大，搜索空间越大，但计算量也增加。\n",
    "\n",
    "- **错误分析**：\n",
    "  - 对翻译结果进行分析，识别常见错误类型，如词汇错误、语法错误和语义错误。\n",
    "  - 通过对错误进行分类和统计，找出模型的薄弱环节。\n",
    "  - 通过调整模型结构、增加数据量或改进训练方法来减少错误。\n",
    "\n",
    "### 3. 使用波束搜索确定可能的翻译\n",
    "\n",
    "- **实现波束搜索**：\n",
    "  - 使用波束搜索算法在翻译模型的解码过程中选择最优翻译路径。\n",
    "  - 保留固定数量的候选序列，逐步扩展和评估每个候选序列。\n",
    "  - 在每一步选择得分最高的前k个候选序列，并将它们作为下一步的输入。\n",
    "\n",
    "- **代码示例**：\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        for seq, score in sequences:\n",
    "            for i in range(len(row)):\n",
    "                candidate = [seq + [i], score * -np.log(row[i])]\n",
    "                all_candidates.append(candidate)\n",
    "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
    "        sequences = ordered[:k]\n",
    "    return sequences\n",
    "\n",
    "# 示例数据\n",
    "data = np.array([[0.1, 0.2, 0.3, 0.4], [0.3, 0.3, 0.2, 0.2], [0.4, 0.1, 0.3, 0.2]])\n",
    "result = beam_search_decoder(data, 2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "### 4. 对机器翻译文本应用 BLEU 分数\n",
    "\n",
    "- **BLEU 分数**：\n",
    "  - BLEU（Bilingual Evaluation Understudy）是评估机器翻译质量的标准指标。\n",
    "  - 通过比较机器翻译结果和参考翻译的重合度来计算。\n",
    "  - 计算方式包括n-gram重合度、BP（Brevity Penalty）等。\n",
    "\n",
    "- **代码示例**：\n",
    "\n",
    "```python\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "reference = [['this', 'is', 'a', 'test']]\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(f'BLEU score: {score}')\n",
    "```\n",
    "\n",
    "### 5. 实施关注模式\n",
    "\n",
    "- **注意力机制（Attention Mechanism）**：\n",
    "  - 在序列到序列模型中，注意力机制通过计算当前时间步与输入序列各个时间步之间的权重来动态调整上下文信息。\n",
    "  - 常用的注意力机制包括Bahdanau Attention和Luong Attention。\n",
    "  - 注意力机制提高了长序列处理的效果，通过赋予输入序列中不同部分不同的权重，使得模型能够关注到输入序列中重要的信息。\n",
    "\n",
    "- **代码示例**：\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class BahdanauAttention(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "```\n",
    "\n",
    "### 6. 训练触发词检测模型并进行预测\n",
    "\n",
    "- **触发词检测**：\n",
    "  - 用于检测音频流中预定义的触发词（例如“Hey Siri”或“OK Google”）。\n",
    "  - 通过训练神经网络模型来识别触发词的特征。\n",
    "  - 触发词检测模型通常包括卷积层、循环神经网络层（如GRU或LSTM）和全连接层。\n",
    "\n",
    "- **代码示例**：\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GRU, Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=196, kernel_size=15, strides=4, input_shape=(Tx, n_freq)),\n",
    "    GRU(units=128, return_sequences=True),\n",
    "    GRU(units=128, return_sequences=False),\n",
    "    Dense(units=1),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 示例数据\n",
    "Tx = 5511  # 输入时间步\n",
    "n_freq = 101  # 频率维度\n",
    "X = np.random.rand(100, Tx, n_freq)\n",
    "y = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model.fit(X, y, epochs=10)\n",
    "```\n",
    "\n",
    "### 7. 合成和处理录音\n",
    "\n",
    "- **音频处理**：\n",
    "  - 使用Librosa库进行音频处理，包括读取音频文件、提取特征（例如梅尔频谱图）、添加噪声等。\n",
    "  - 常用的特征提取方法包括MFCC（梅尔频率倒谱系数）、梅尔频谱图等。\n",
    "\n",
    "- **代码示例**：\n",
    "\n",
    "```python\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def load_audio_file(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    return y, sr\n",
    "\n",
    "def extract_mel_spectrogram(y, sr, n_mels=128):\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=n_mels)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    return S_dB\n",
    "\n",
    "# 示例使用\n",
    "y, sr = load_audio_file('example.wav')\n",
    "mel_spectrogram = extract_mel_spectrogram(y, sr)\n",
    "print(mel_spectrogram.shape)\n",
    "```\n",
    "\n",
    "### 8. 创建训练/开发数据集\n",
    "\n",
    "- **数据集构建**：\n",
    "  - 从原始音频数据中提取特征，创建用于训练和开发的音频样本。\n",
    "  - 需要包括正样本（包含触发词的音频）和负样本（不包含触发词的音频）。\n",
    "  - 数据增强技术（如添加噪声、时间拉伸、音调变化等）可以用于增加数据集的多样性，提高模型的鲁棒性。\n",
    "\n",
    "### 9. 构建语音识别项目\n",
    "\n",
    "- **语音识别**：\n",
    "  - 使用深度学习模型进行语音识别，将音频转换为文本。\n",
    "  - 常用的模型包括CTC（Connectionist Temporal Classification）和Seq2Seq模型。\n",
    "  - 语音识别系统通常包括声学模型、语言模型和解码器。\n",
    "\n",
    "- **代码示例**：\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, LSTM, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_shape = (None, 128, 64, 1)\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = TimeDistributed(Flatten())(x)\n",
    "x = LSTM(128,return_sequences=True)(x)\n",
    "x = LSTM(128, return_sequences=False)(x)\n",
    "outputs = Dense(len(characters), activation=‘softmax’)(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=‘adam’, loss=‘categorical_crossentropy’, metrics=[‘accuracy’])\n",
    "# 示例数据\n",
    "X = np.random.rand(100, 128, 64, 1)\n",
    "y = np.random.randint(len(characters), size=(100, 1))\n",
    "\n",
    "model.fit(X, y, epochs=10)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
