# 2024.07.31讲座（第二讲）

## 第一部分：LLM 基础知识

### 1.1 Transformer 架构

- **Transformer 架构简介**：
  - Transformer 是一种用于自然语言处理（NLP）的神经网络架构，主要特点是其自注意力机制。
  - Transformer 由编码器（Encoder）和解码器（Decoder）两部分组成。
  - 编码器负责将输入序列编码为一系列向量表示，解码器根据这些向量生成输出序列。

- **自注意力机制**：
  - 自注意力机制允许模型在处理每个词时参考输入序列中的所有词，从而更好地理解上下文。
  - 通过计算输入序列中每个词对其他词的注意力权重，自注意力机制能够捕捉词与词之间的依赖关系。

- **编码器和解码器的结构**：
  - 每个编码器和解码器层都包含一个多头自注意力机制和一个前馈神经网络。
  - 多头自注意力机制能够在不同的子空间中计算注意力，有助于捕捉更丰富的特征。
  - 前馈神经网络用于对自注意力机制的输出进行进一步处理和转换。

### 1.2 语言模型的简史

- **早期语言模型**：
  - 早期的语言模型如 n-gram 基于统计方法，通过计算词序列的联合概率来进行语言建模。
  - 这些模型的主要缺点是无法有效捕捉长距离依赖关系。

- **基于神经网络的模型**：
  - 随着计算能力的提高和数据的增加，基于神经网络的语言模型逐渐成为主流。
  - RNN（循环神经网络）和 LSTM（长短期记忆网络）能够捕捉序列数据中的长距离依赖关系，但在处理长序列时仍存在一些问题。

- **Transformer 的出现**：
  - Transformer 架构的提出标志着现代语言模型的开始，如 BERT、GPT 系列。
  - Transformer 通过自注意力机制解决了 RNN 和 LSTM 在处理长序列时存在的问题，显著提高了模型的性能。

### 1.3 自然语言处理范式

- **监督学习**：
  - 监督学习是指使用标注数据训练模型，以便模型能够在给定输入时预测正确的输出。
  - 常见的监督学习任务包括分类、回归和序列标注等。

- **半监督学习**：
  - 半监督学习结合了少量标注数据和大量未标注数据进行模型训练。
  - 通过利用未标注数据，模型可以在保持较高性能的同时减少对标注数据的依赖。

- **无监督学习**：
  - 无监督学习是指使用未标注数据训练模型，以便模型能够发现数据中的结构和模式。
  - 常见的无监督学习任务包括聚类、降维和密度估计等。

- **迁移学习和微调**：
  - 随着预训练模型的发展，迁移学习和微调成为主流。
  - 通过在大规模数据上预训练模型，然后在特定任务上进行微调，可以显著提高模型的性能。

### 1.4 Prompt 工程

- **Prompt 工程简介**：
  - Prompt 工程是一种利用预训练模型生成特定输出的方法。
  - 通过设计适当的提示（prompt），可以引导模型生成所需的文本。

- **Prompt 的设计原则**：
  - 清晰明了：Prompt 应该尽可能简洁明了，避免歧义。
  - 具体明确：Prompt 应该具体明确，以便模型能够理解任务的要求。
  - 避免偏见：Prompt 设计应避免引入偏见和歧视。

- **Prompt 工程的应用**：
  - 生成任务：如文本生成、摘要生成等。
  - 理解任务：如问答、文本分类等。
  - 推理任务：如逻辑推理、常识推理等。

### 1.5 参数高效微调

- **参数高效微调简介**：
  - 参数高效微调是指在有限的计算资源下，对预训练模型进行微调，以适应特定任务。
  - 这种方法通过只微调部分模型参数，减少了计算和存储开销。

- **常见的参数高效微调方法**：
  - Adapter：在预训练模型的层与层之间插入适配器模块，只微调适配器参数。
  - LoRA（Low-Rank Adaptation）：通过低秩分解减少微调参数的数量。
  - Prefix Tuning：在输入序列前添加一段可微调的前缀，从而只微调前缀参数。

## 第二部分：应用案例

### 2.1 叙事理解

#### NarrativePlay

- **步骤**：
  1. 加载叙述。
  2. 选择一个角色。
  3. 与叙述中的其他角色进行对话。

- **框架**：
  - 角色特征：名称、意图、关系（家庭、朋友、竞争对手等）、技能。
  - 外貌和声音：年龄、性别、发色/发型、眼睛颜色等。
  - 经历的事件：角色涉及、地点、描述、对话等。

- **设置可视化**：
  - **常见问题**：同一位置在叙述中多次提及，模糊的描述复杂了设置提取任务。
  - **解决方法**：使用稳定扩散模型生成事件设置描述的图像。

- **响应生成**：
  1. 发起与用户的对话。
  2. 生成用户输入的响应。

- **角色中心叙事理解**：
  - **特征**：角色常常采用多重身份或别名。角色之间的关系常常由不完整和不确定的信息表征（公共关系、秘密关系和推断关系）。
  - **Conan 数据集**：
    - 目标：选取 100 个高质量叙述，定义关系类别的层次结构。
    - 人类注释流程：角色提取、实体链接、冲突检测和关系优化。

- **角色关系提取**：
  - 流程：输入包含角色和相应叙述，角色提取和实体链接与冲突识别。

- **挑战**：
  - 复杂信息：各个角色的信息包括秘密、误解、为自我利益或特定目标生成的谎言，以及由疾病引起的妄想。
  - 长叙述：LLMs 通常表现出“中间丢失”的现象。

#### 剧本杀（Murder’s Game）

- **游戏流程**：
  1. 角色选择。
  2. 剧本熟悉。
  3. 讨论模拟。
  4. 最终决策。

- **玩家规划策略**：
  1. 初始化：提供自我介绍并初始化传感器和记忆。
  2. 搜索：通过提问其他代理搜索进一步信息。
  3. 近似：根据收到的响应调整怀疑程度和搜索领域。
  4. 投票：根据最终理解确定凶手。

- **评估**：
  - 结果：Player* 在多个方面表现优秀。
  - 运行成本：Player* 在运行成本方面也有较好的表现。

### 2.2 医疗健康中的大语言模型

- **大语言模型在医疗健康领域的应用**：
  - **医疗查询**：帮助医生和患者快速查询医学知识和疾病信息。
    - 通过自然语言处理技术，模型可以理解医生和患者的查询，并提供准确的医学信息。
    - 例如，患者可以通过对话接口询问关于某种疾病的症状、治疗方法和预防措施，模型能够根据医学文献提供详细的回答。
  
  - **医学检查**：协助医生分析和解释医学影像和检查结果，提高诊断准确性。
    - 模型可以通过训练在大量医学影像数据上，识别出影像中的异常区域，如肿瘤、炎症等。
    - 例如，医生可以将患者的CT扫描图像输入模型，模型能够标记出可能的异常区域，辅助医生做出诊断决策。

  - **医疗助手**：提供病历总结、病人管理和个性化医疗建议。
    - 模型可以帮助医生整理患者的病历，总结关键信息，生成诊断报告。
    - 例如，医生可以通过语音输入患者的病史和症状，模型能够自动生成病历总结，并提供进一步的检查和治疗建议。

  - **药物研发**：加速新药发现，通过分析大量的医学文献和数据，发现潜在的药物靶点和疗法。
    - 模型可以通过自然语言处理技术，分析医学文献中的药物研究数据

，发现新的药物靶点和疗法。
    - 例如，研究人员可以输入特定疾病的关键词，模型能够提取相关文献中的关键信息，帮助发现新的药物靶点。

  - **健康监测**：通过分析患者的日常健康数据，提供早期预警和健康管理建议。
    - 模型可以通过分析患者的健康监测数据，如心率、血压、血糖等，发现异常趋势，并提供健康管理建议。
    - 例如，患者可以通过可穿戴设备收集日常健康数据，模型能够实时分析数据，提供早期预警和个性化的健康管理建议。

### 2.3 教育中的大语言模型

- **大语言模型在教育领域的应用**：
  - **个性化学习**：根据学生的学习进度和兴趣，提供定制化的学习内容和资源。
    - 模型可以通过分析学生的学习行为和成绩，了解学生的学习需求和兴趣，提供个性化的学习建议。
    - 例如，学生可以通过在线学习平台完成学习任务，模型能够根据学生的表现推荐适合的学习资源和练习题。

  - **自动评分**：利用自然语言处理技术，自动评分作文和简答题，减轻教师的负担。
    - 模型可以通过训练在大量评分数据上，学习评分标准和评分规则，自动为学生的作文和简答题打分。
    - 例如，教师可以将学生的作文输入模型，模型能够根据评分标准给出分数，并提供评分反馈。

  - **教育资源生成**：生成教学材料、练习题和教学大纲，帮助教师准备课程。
    - 模型可以通过分析教材和教学大纲，自动生成教学材料和练习题，帮助教师准备课程内容。
    - 例如，教师可以输入课程主题，模型能够生成相应的教学大纲、教学材料和练习题。

  - **学习辅助**：为学生提供实时答疑和学习建议，提高学习效率。
    - 模型可以通过自然语言处理技术，理解学生的提问，提供准确的回答和学习建议。
    - 例如，学生可以通过对话接口询问数学题的解题思路，模型能够提供详细的解题步骤和思路。

  - **语言学习**：通过对话和写作练习，帮助学生提高语言技能。
    - 模型可以通过对话和写作练习，提供语言学习的反馈和建议，帮助学生提高语言技能。
    - 例如，学生可以通过对话接口练习口语，模型能够提供语法纠正和表达建议。

  - **教育数据分析**：分析学生的学习行为和成绩，提供数据驱动的教学决策支持。
    - 模型可以通过分析学生的学习数据，发现学生的学习趋势和问题，提供数据驱动的教学决策支持。
    - 例如，学校可以通过分析学生的成绩数据，发现学生在某些科目上的学习问题，调整教学策略。

## 第三部分：评估

### 3.1 评估基准（专注于QA和MRC任务）

#### 评估任务

**NLP任务**
- 自然语言理解：情感分析、文本分类、自然语言推理等。
- 自然语言生成：摘要、对话、机器翻译、问答等。
- 推理：数学推理、常识推理、逻辑推理、领域特定推理。
- 多语言处理
- 事实性：保持与已知事实的一致性，避免生成误导或错误的信息，并有效学习和回忆事实知识。

**可信AI**
- 鲁棒性、伦理和偏见、可信度

**社会科学**
- 计算社会科学任务、法律任务、心理学

**自然科学与工程**
- 数学、一般科学、工程

**医疗应用**
- 医疗查询、医学检查、医疗助手

**代理应用**

**其他应用**
- 教育、搜索和推荐、性格测试、特定任务

#### 评估数据集

**通用基准**
- MMLU、C-Eval、OpenLLM、DynaBench、Chatbot Arena、AlpacaEval、HELM、BIG-bench、PandaLM、BOSS、GLUE-X、KoLA、AGIEval、PromptBench、MT-Bench、LLMEval

**特定基准**
- SOCKET、Choice-75、CUAD、TRUSTGPT、MATH、APPS、CELLO、EmotionBench、CMMLU、API-Bank、M3KE、UHG-Eval、ARB、MultiMedQA、CVALUES、ToolBench、FRESHQA、CMB、MINT、Dialogue CoT、M3Exam、GAOKAO-Bench、SafetyBench

**多模态基准**
- MME、MMBench、SEED-Bench、MM-Vet、LAMM、LVLM-eHub

#### 评估方法

**自动评估**
- 准确性：精确匹配、准精确匹配、F1分数、ROUGE分数
- 校准：预期校准误差、曲线下面积
- 公平性：人口统计平等差异、平等机会差异
- 鲁棒性：攻击成功率、性能下降率

**人工评估**
- 评估人员数量：足够的代表性、统计显著性
- 评估标准：准确性、相关性、流畅性、透明性、安全性、人类一致性
- 评估人员的专业水平：相关领域的专业知识、任务熟悉度、方法培训

#### 机器阅读理解 vs. QA

**任务比较**
- 阅读理解：提供证据段落，问题和答案都是生成的
- 开放域QA：无需证据段落
- 无监督QA：没有证据和答案
- 强监督QA：提供证据和答案
- 弱监督QA：提供证据段落，答案是生成的
- 封闭检索QA：启发式证据和答案
- 开放检索QA：学习证据和答案

**MRC评估基准**
- SQuAD：单段落维基百科文章
- HotpotQA：多个支持段落
- NarrativeQA：基于故事、书籍、电影脚本和人类摘要生成的问题
- ReClor：基于逻辑推理问题的标准化考试

**QA评估基准**
- MS MARCO：通过搜索引擎检索问题
- TriviaQA：从维基百科和网络上收集的问题
- Natural Questions：从维基百科检索的问题

### 3.2 评估方法

- **自动评估**：
  - **Lexical Matching**：
    - 词汇匹配：精确匹配准确性、部分 token 级别的重叠（F1）分数。
    - 现有自动化评估方法存在的问题：无法识别超出金标准答案列表的可信答案，在长答案和开放形式答案中表现不佳。

  - **LLM-Eval**：
    - 单个 LLM 生成不同评估维度的分数。
    - 观察结果：不同评分范围（0-5，0-100）具有相似性能，整体表现优于其他基线。
    - 不同的 LLM 也有不同表现，Claude 和 ChatGPT 在所有维度上表现优于 GPT-3.5。
    - 不同的解码策略：贪婪解码通常在所有评估维度上表现更好。

  - **ChatEval**：
    - LLM 代理进行评估。
    - 单一代理方法：单一代理生成响应后进行评估。
    - 多代理辩论方法：多个代理讨论后生成评估结果。

  - **Prometheus**：
    - 开源的 LM 评估器，基于包含反馈收集的数据集进行训练。
    - 通过定制评分标准和参考答案进行评估，生成反馈和评分。

### 3.3 评估指标

- **自动评估指标**：
  - 准确性：精确匹配、准精确匹配、F1分数、ROUGE分数。
  - 校准：预期校准误差、曲线下面积。
  - 公平性：人口统计平等差异、平等机会差异。
  - 鲁棒性：攻击成功率、性能下降率。

- **人工评估指标**：
  - 评估人员数量：足够的代表性、统计显著性。
  - 评估标准：准确性、相关性、流畅性、透明性、安全性、人类一致性。
  - 评估人员的专业水平：相关领域的专业知识、任务熟悉度、方法培训。

### 3.4 大语言模型的自我优化方法

- **反思机制（Reflection）**：
  - 基本反思流程：用户请求生成初始响应，反思模型对初始响应进行反思和修改，重复多次直到生成最终响应。
  - 决策、编程和推理任务中的应用：通过反思机制改进模型的决策、编程和推理

能力。

- **自我优化方法**：
  - Actor、Evaluator 和 Self-Reflection 模型的交互：Actor 模型生成行动序列，Evaluator 模型评估行动序列，Self-Reflection 模型根据反馈生成反思文本。
  - 短期记忆和长期记忆的应用：短期记忆用于存储行动轨迹，长期记忆用于存储反思模型的输出。

### 3.5 评估挑战

- **动态和不断发展的评估**：
  - 现有评估协议依赖静态和公开的基准，可能导致训练数据污染。
  - 更好地与伦理和偏见相关的新兴需求对齐。

- **统一的评估方法**：
  - 支持所有类型的任务，如价值对齐、安全性、验证、跨学科研究、微调等。

- **完整的行为评估**：
  - 通用人工智能（AGI）模型应在开放环境中进行评估，被视为完全智能的机器，理论心智（ToM）能力应得到更好的探索。
