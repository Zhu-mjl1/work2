# Notes: Generative Image Dynamics 
*CVPR-2024 Best Paper, Zhengqi Li, Richard Tucker, Noah Snavely, Aleksander Holynski*

### 1. 研究背景和动机
自然世界中，甚至看似静止的场景也会因为风、水流、呼吸等自然节律而产生微妙的振荡运动。在视觉内容合成中，模拟这些运动至关重要，因为人类对运动的敏感性使得没有运动或运动不真实的影像会显得怪异或不真实。
尽管人类能够轻松地从静止图像中想象出可能的运动，但让机器学习模型产生或理解逼真的场景运动并非易事。现实中的运动是场景底层物理动态的结果，例如物体的质量、弹性等属性，但这些属性在大规模上难以测量和捕捉。
然而，某些应用并不需要这些精确的物理属性测量，比如仅通过分析观察到的二维运动，就可以模拟场景中的合理动态。

### 2. 研究目标
这篇文章的主要目标是开发一种方法，通过从单张RGB图像生成一个“谱体积”（Spectral Volume），进而生成长时间的密集像素轨迹，以此模拟场景中的运动。生成的运动可以用于以下应用场景：
- 将静止图像转换为无缝循环的视频。
- 允许用户与图像中的物体进行交互，生成响应用户输入的真实动态模拟。

### 3. 方法概述
文章提出的模型包含以下几个关键步骤和模块：

#### 3.1 运动表示（Motion Representation）
文章采用“谱体积”（Spectral Volume）来表示视频中的运动轨迹。谱体积是通过对像素级运动轨迹进行傅里叶变换得到的频域表示，特别适用于那些表现出振荡动态的场景，例如风中摇曳的树木和花朵。这个表示方法能够高效地解释像素值的长期变化。

#### 3.2 运动预测模块（Motion Prediction Module）
为了从单张图像预测谱体积，文章采用了一种潜在扩散模型（Latent Diffusion Model, LDM）。具体而言：
- **输入图像**：首先对输入的RGB图像进行处理，通过扩散模型生成一个谱体积。
- **频率协调去噪（Frequency-Coordinated Denoising）**：该扩散模型逐频率带生成谱体积的系数，通过一个共享的注意力模块协调不同频带之间的预测。每个频率带预测的结果被整合为一个整体的谱体积。
- **频率自适应归一化（Frequency Adaptive Normalization）**：为了确保稳定的训练和去噪过程，文章提出了一种自适应的频率归一化方法，分别对每个频率进行归一化，防止高频分量被压缩至接近零，从而避免生成不准确的运动。

#### 3.3 图像渲染模块（Image-Based Rendering Module）
预测得到的谱体积可以转换为运动纹理，然后利用图像基渲染技术生成未来的动画帧。渲染模块通过以下步骤工作：
- **运动纹理生成**：通过对谱体积进行逆傅里叶变换，生成时间域的运动纹理。
- **图像前向映射（Forward Warping）**：将输入图像通过运动场进行前向映射，生成未来的动画帧。为了避免映射过程中出现的空洞问题，使用了一种基于特征金字塔的Softmax Splatting策略。
- **图像合成**：将映射后的图像特征输入图像合成网络，生成最终的渲染图像。

### 4. 实验与结果
文章通过多种实验验证了所提出方法的有效性，并展示了以下几个主要应用场景：

#### 4.1 图片到视频生成（Image-to-Video Generation）
通过预测输入图像的谱体积并生成运动纹理，系统能够将静止的图像动画化。通过线性插值运动纹理，可以生成慢动作视频；通过调整谱体积系数的幅度，可以放大或缩小动画运动。

#### 4.2 无缝循环视频生成（Seamless Looping Video Generation）
许多应用场景需要生成无缝循环的视频，文章提出了一种运动自引导（Motion Self-Guidance）技术，在推理过程中对运动去噪采样过程施加显式的循环约束，确保生成的每个像素在开始帧和结束帧的位置和速度尽可能一致。

#### 4.3 单张图片生成交互动态（Interactive Dynamics from a Single Image）
通过将谱体积解释为图像空间的模态基，文章实现了从单张图片生成交互动态。用户可以对图片中的物体施加力，系统会模拟物体的响应，并以动画的形式展现出来。

### 5. 定量与定性分析
文章通过多种指标和可视化方法验证了模型的效果：

#### 5.1 定量分析（Quantitative Analysis）
使用了以下指标来评估生成视频的质量和时序一致性：
- **Frechet Inception Distance (FID)**：用于评估单帧图像的生成质量。
- **Kernel Inception Distance (KID)**：用于评估生成帧和真实帧的分布差距。
- **Frechet Video Distance (FVD)** 和 **Dynamic Texture Frechet Video Distance (DT-FVD)**：评估生成视频的质量和时间一致性，特别是用于捕捉自然振荡运动的动态纹理。

#### 5.2 定性分析（Qualitative Analysis）
通过时空X-t切片的可视化方式，展示了生成的视频与真实参考视频在动态模式上的相似性。文章还展示了与现有方法的对比，证明所提出的方法在生成的视频动态上更接近真实场景。

### 6. 消融研究（Ablation Study）
文章还进行了多项消融研究，验证了各个设计选择对模型性能的影响。例如：
- 选择不同数量的频率带（K = 4, 8, 16, 24）进行实验，发现使用16个频率带可以实现较好的视频预测质量。
- 去除频率自适应归一化和频率协调去噪模块，结果表明这些设计对提升模型性能至关重要。

### 7. 结论与未来工作
文章最后讨论了方法的局限性：
- 由于方法仅预测谱体积的低频部分，因此可能无法准确模拟非振荡运动或高频振动。
- 在场景中有细小物体移动或大位移物体的情况下，生成的运动质量可能下降。
- 如果需要生成大量新的不可见内容，生成的运动可能会退化。
