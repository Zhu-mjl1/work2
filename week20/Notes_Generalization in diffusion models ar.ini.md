## Generalization in diffusion models arises from geometry-adaptive harmonic representation

### 1. **引言 (Introduction)**
   - **背景**：深度神经网络（DNN）在高维图像密度学习中展现了卓越的能力，特别是在扩散模型中。通过去噪模型，DNN能够生成高质量的图像样本。
   - **挑战**：尽管模型在小数据集上训练，存在过拟合和记忆训练集的问题，是否真正学到了数据的“连续”密度仍然是个问题。
   - **研究目标**：本研究旨在探讨DNN在扩散模型中的泛化能力，理解其如何从小数据集学到高维图像密度，并揭示其中的归纳偏置。

### 2. **扩散模型的方差与去噪泛化 (Diffusion Model Variance and Denoising Generalization)**
   - **扩散模型与去噪**：扩散模型通过训练去噪器，估计图像密度的得分函数，然后通过逆扩散过程生成新样本。核心问题是理解这些模型如何在高维空间中学习连续密度。
   - **从记忆到泛化的过渡**：当训练数据量增加时，模型从记忆训练数据过渡到泛化，最终生成的样本趋于相似。这表明随着数据集的增大，模型的方差逐渐减小，最终实现泛化。

### 3. **归纳偏置 (Inductive Biases)**
   - **定义**：归纳偏置是指网络结构和优化算法在假设空间上施加的隐式先验。它决定了模型能够在相对较少的训练数据下实现泛化。
   - **去噪器中的自适应基 (Adaptive Basis in Denoising)**：
     - **雅可比矩阵分析**：通过对去噪器的雅可比矩阵进行特征分解，发现模型在自适应基中执行缩减操作，这些基与输入图像的几何特征相适应。
     - **特征向量的几何自适应性**：特征向量表现为沿轮廓和均匀区域的振荡模式，模型通过这些特征向量来执行去噪操作。

### 4. **对齐的归纳偏置与最优性 (Aligned Inductive Biases and Optimality)**
   - **几何自适应谐波基 (GAHB)**：研究表明，当DNN在图像上训练时，它们倾向于学习几何自适应谐波基（GAHB），这种基能够实现接近最优的去噪性能。
   - **Cα 图像与带状基 (Cα Images and Bandlet Bases)**：
     - **Cα 类图像**：对于几何Cα类图像，GAHB被证明是近似最优的去噪基。DNN能够学习到与带状基相似的自适应基，实现了与最优基相似的性能。
     - **实验结果**：在Cα 图像上，DNN去噪器实现了接近最优的PSNR斜率，验证了GAHB作为DNN归纳偏置的合理性。

### 5. **未对齐的归纳偏置与次优性 (Mis-Aligned Inductive Biases and Suboptimality)**
   - **低维流形上的表现**：
     - **实验设计**：研究了在低维流形上训练的DNN去噪器。最优去噪器应该投影到流形的切空间，但DNN保留了部分GAHB成分，导致了次优的PSNR性能。
     - **次优性表现**：随着噪声水平降低，未对齐的GAHB成分导致了模型次优的去噪表现。
   - **随机打乱图像上的表现**：
     - **实验设计**：训练了一个随机打乱像素的面部图像数据集上的去噪器。最优基应该是原始基的打乱版本。
     - **次优性表现**：DNN去噪器在这种情况下表现不佳，显示出归纳偏置与数据属性不匹配时性能显著下降。

### 6. **讨论 (Discussion)**
   - **总结**：DNN在扩散模型中通过学习几何自适应谐波基实现了强泛化能力，即使在训练数据较少的情况下。这种泛化能力背后的关键在于DNN的归纳偏置与图像分布的高度对齐。
   - **开放问题**：研究提出了GAHB反映了DNN的归纳偏置，但GAHB的数学定义以及它们如何从DNN的计算架构中产生仍需进一步研究。

### 7. **实验细节 (Experimental Details)**
   - **训练与架构**：
     - **无偏卷积神经网络**：使用了无偏卷积神经网络（BF-CNN），由21层卷积层组成，训练过程中移除了所有加性常数。
     - **数据集**：实验在CelebA和LSUN卧室数据集上进行，分别调整为40×40和32×32分辨率。
   - **采样算法**：
     - **算法**：采样使用了确定性的逆扩散算法，控制计算效率与视觉质量的权衡。

### 8. **附加实验结果 (Additional Numerical Results)**
   - **CelebA子集相似性**：分析了CelebA数据集中非重叠子集间的相似性，验证了模型在不同子集上的泛化能力。
   - **LSUN卧室数据集上的泛化**：在LSUN数据集上进行的实验验证了模型在不同非重叠子集上生成几乎相同的样本，进一步支持了泛化的结论。

### 9. **数学推导 (Mathematical Derivations)**
   - **Miyasawa关系**：提供了最小均方误差（MMSE）估计与得分的关系推导。
   - **KL散度控制**：展示了如何将得分匹配误差转化为去噪目标，并推导出KL散度的上限。
   - **Stein无偏风险估计（SURE）目标**：推导了Stein无偏风险估计公式，用于评估去噪器的性能。

### 10. **几何Cα 图像 (Geometric Cα Images)**
   - **Cα 图像合成**：描述了生成几何Cα图像的算法步骤，主要通过在傅里叶域中进行积分来实现。
