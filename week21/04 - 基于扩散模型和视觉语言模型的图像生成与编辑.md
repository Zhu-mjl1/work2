## 走进顶尖AI科学家04期-基于扩散模型和视觉语言模型的图像生成与编辑

### 1. 视觉语言模型（Vision Language Models）

#### 1.1 模型概述
- 视觉语言模型（VLMs）是一类能够同时处理图像（视觉）和文本（语言）的模型，通过结合视觉和语言信息提高模型对图像内容的理解和生成能力。

#### 1.2 学习策略
- **对比学习（Contrastive Learning）**：将图像和文本对齐到一个联合特征空间中，模型在视觉和文本表示之间找到共同的特征空间。
- **PrefixLM**：通过使用图像作为语言模型的前缀，联合学习图像和文本嵌入，使模型在生成文本时能够考虑图像内容。
- **多模态融合与交叉注意力（Multi-modal Fusing with Cross Attention）**：通过交叉注意力机制，将视觉信息融入到语言模型的不同层次中，以提高模型在处理复杂任务时的表现。
- **无训练（No Training）**：通过迭代优化技术，使用独立的视觉和语言模型生成结果，无需在模型之间进行额外的联合训练。

### 2. 扩散模型（Diffusion Models）

#### 2.1 概述
- 扩散模型是一类基于似然的生成模型，通过马尔可夫链进行数据的生成过程，逐渐注入噪声并通过逆向过程去除噪声，恢复原始数据。

#### 2.2 训练过程与算法
- **训练过程**：
  - **噪声估计**：模型作为噪声估计器被训练，在每一步的马尔可夫链中估计并去除噪声。
  - **采样过程**：扩散模型通过迭代方式生成样本，每次迭代逐渐减少数据中的噪声，直到恢复到清晰图像。
  
- **算法**：
  - **算法1（训练）**：通过变分下界优化，模型学习识别并恢复无噪声数据。
  - **算法2（采样）**：模型通过逆向扩散过程，从噪声生成无噪声的图像。

### 3. 图像生成（Image Generation）

#### 3.1 生成模型概述
- **生成模型**：设计用于“生成或合成数据”的统计模型，包括GAN、VAE和扩散模型等。
- **深度生成模型**：生成模型与深度神经网络结合，生成更复杂和高质量的数据。

#### 3.2 主要类型
- **GAN**：由生成器和判别器组成，生成器生成逼真图像，判别器区分真实和生成图像，两者通过对抗训练相互提升。
- **VAE**：编码器将输入图像编码为潜在变量，通过解码器从这些变量重构图像，VAE通过最大化变分下界训练。
- **扩散模型（Diffusion Models）**：通过逐渐去除噪声，从随机噪声生成图像。

#### 3.3 模型的两个主要问题
- **模式覆盖（Mode Coverage）**：生成模型是否覆盖所有可能的样本模式，即生成多样化的图像。
- **模式崩溃（Mode Collapse）**：生成模型是否集中生成少数样本模式，导致生成图像多样性不足。

#### 3.4 基于扩散模型的图像生成
- **文本生成图像**：
  - **主要工具**：Dall-E 系列、Imagen、Stable Diffusion、Midjourney。
- **个性化图像生成**：
  - **文本反转**：通过文本反转技术微调扩散模型，生成个性化图像，如个人物品或特定艺术风格的图像。

### 4. 图像编辑（Image Editing）

#### 4.1 基于扩散的图像编辑
- **输入条件**：扩散模型可以使用文本描述、参考图像、掩码、分割图、布局、姿势、音频等作为输入条件，通过自然语言或视觉指令指导图像编辑。

#### 4.2 编辑方法
- **Prompt-to-Prompt**：通过文本描述和多模态融合，实现从一个图像到另一个图像的编辑，不改变图像整体内容。
- **MagicMix**：通过语义混合，结合不同语义概念生成新颖的图像内容，如狗形咖啡机。
- **DiffEdit**：基于掩码的图像编辑方法，通过掩码指导扩散模型的生成，控制编辑区域和内容。

### 5. 讨论（Discussion）
- **讨论要点**：
  1. **精确语言引导的图像编辑**：通过自然语言描述精确控制图像编辑，使编辑结果更加符合用户意图。
  2. **个性化**：根据用户偏好生成个性化图像，满足定制化需求。
  3. **扩展到3D编辑**：探讨将2D图像编辑技术扩展到3D对象编辑中的可能性。
  4. **变形处理**：研究在图像生成和编辑中处理对象形变，保证生成结果的合理性和真实性。
