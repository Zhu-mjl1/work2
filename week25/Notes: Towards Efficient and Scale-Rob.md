# Notes: Towards Efficient and Scale-Robust UHD Image Demoiréing

## Abstract
文章提出了一种高效且鲁棒的网络架构（ESDNet），专门解决4K超高清图像中的摩尔纹问题。为了提高网络的多尺度处理能力，同时保持计算的高效性，文章设计了一个**语义对齐的多尺度感知模块（SAM）**。此外，文章还提出了首个大规模的4K超高清摩尔纹数据集——**UHDM**，用于评估现有方法和改进模型的性能。实验结果表明，ESDNet在UHDM数据集以及其他三个公开的去摩尔纹数据集上均取得了显著的性能提升，尤其是在PSNR、SSIM和LPIPS等图像质量评估指标上表现尤为出色。

---

## 1. Introduction

### 背景
摩尔纹现象通常发生在相机传感器与被拍摄对象的高频纹理之间，主要由频率混叠导致。当相机的采样频率不足以捕捉被拍摄对象的细节时，出现了不真实的波纹状伪影。摩尔纹不仅影响视觉质量，而且对后续的图像处理如图像增强、图像修复产生负面影响。

特别是在超高清(4K)图像中，摩尔纹现象更为严重。随着4K及以上分辨率图像在移动设备拍摄中的普及，如何有效去除摩尔纹已成为一个紧迫的挑战。当前的去摩尔纹方法主要集中于低分辨率场景，较少关注4K等高分辨率图像的去摩尔纹任务。

### 现有问题
现有去摩尔纹方法可以粗略地分为两类：
1. **多阶段处理方法**：如FHDe²Net，这类方法通过在低分辨率阶段处理大范围摩尔纹，在高分辨率阶段进一步细化纹理。尽管这些方法在某些任务中表现良好，但当应用于4K图像时，计算开销巨大，不利于实际应用。
2. **多尺度表示方法**：如MBCNN，利用网络不同深度的特征来构建多尺度表示，能够在一定程度上提高处理效率。然而，这些方法无法在同一语义级别上对齐多尺度特征，导致融合时可能出现特征错位，从而限制了去摩尔纹的效果。

### 目标
为了应对上述挑战，文章提出了一个轻量级的**语义对齐的多尺度感知模块（SAM）**，旨在增强网络对不同尺度摩尔纹的处理能力，而不会带来巨大的计算成本。通过将SAM模块集成到简单的**编码器-解码器网络架构**中，文章设计了**ESDNet**，并证明该网络在去除4K高分辨率图像摩尔纹时具有很好的表现。

---

## 2. Related Work

### 图像去摩尔纹
在图像去摩尔纹任务中，过去的方法多基于合成数据进行训练，例如Liu等人提出的通过模拟相机成像过程的合成数据集，并使用生成对抗网络（GAN）框架进行摩尔纹去除。然而，基于合成数据的训练模型往往难以处理真实世界中的摩尔纹问题，这种“sim-to-real gap”极大限制了模型的实际应用。

Sun等人首次提出了**TIP2018**数据集，专门针对真实世界的摩尔纹去除任务，并设计了一个多尺度网络（DMCNN）来应对不同类型的摩尔纹。尽管取得了一定的进展，然而在处理4K及更高分辨率图像时，现有方法仍然表现不佳，主要原因是这些方法难以同时在保证精度的前提下降低计算成本。

### 图像修复
图像修复任务中，残差学习（Residual Learning）和密集连接网络（Dense Connection）技术被广泛应用于低级视觉任务，如图像去噪、超分辨率等。这些技术有助于构建深层神经网络，从而能够捕捉到更加丰富的图像细节。此外，感知损失（Perceptual Loss）和生成损失（Generative Loss）在保持图像结构和语义信息方面发挥了关键作用，在摩尔纹去除任务中，这些损失函数同样至关重要。

### 多尺度网络
多尺度网络在计算机视觉任务中表现突出，尤其是在图像分割和超分辨率任务中。**U-Net**是一个经典的多尺度网络，通过**编码器-解码器结构**来提取多尺度信息，并通过skip connections增强解码器中的特征。为了进一步保留高分辨率特征，HRNet等网络提出了全分辨率残差网络，能够在不同尺度上处理特征。然而，这些方法在摩尔纹任务中，面临着**如何在不同语义级别上有效融合多尺度特征**的挑战。

---

## 3. UHDM Dataset

### 数据集构建
针对现有4K图像数据集分辨率不足、场景不够丰富的问题，文章提出了一个全新的、真实世界的**UHDM数据集**。该数据集包含了大量的真实4K分辨率摩尔纹图像，涵盖了不同的场景、光照条件和拍摄设备，能够更好地模拟现实生活中的摩尔纹问题。与现有的如FHDMi和TIP2018等数据集相比，UHDM数据集的图像分辨率更高，数据量更大，适用于训练和测试针对超高清图像的去摩尔纹模型。

### 数据集使用
在模型训练阶段，文章使用从4K图像中裁剪的768×768大小的图像块进行训练。通过裁剪操作，确保在保持高分辨率的同时，减少每次训练时的计算成本。在评估阶段，文章使用完整的4K图像来评估去摩尔纹效果，采用常见的图像质量评价指标如PSNR（峰值信噪比）、SSIM（结构相似性指数）和LPIPS（感知相似性）来量化图像修复的效果。

---

## 4. Methodology

### 4.1 Network Architecture
文章提出的**ESDNet**网络基于一个简单的编码器-解码器结构。该结构能够通过编码器逐步下采样图像特征，在解码器部分逐步恢复高分辨率图像。为避免信息丢失，编码器和解码器之间通过**skip connections**直接连接不同层次的特征。网络的核心创新在于引入了**语义对齐的多尺度感知模块（SAM）**，该模块能够在不同的语义级别对齐多尺度特征，确保不同尺度下的特征不会发生错位，从而提高去摩尔纹的准确性。

#### SAM模块
- **金字塔上下文提取**：SAM模块通过一个金字塔上下文提取模块来从图像的不同尺度提取特征。首先，通过双线性插值将特征映射至三个不同的尺度，然后通过五个卷积层提取出多尺度特征。这些多尺度特征来自相同的语义级别，确保在后续的融合中不会出现语义错位。
- **跨尺度动态融合**：为了充分利用不同尺度的特征，SAM模块采用了一种自适应的跨尺度动态融合策略。通过全局平均池化操作，计算每个尺度特征的权重，这些权重通过一个MLP模块（多层感知机）进行动态学习，确保不同尺度特征的权重能够根据具体的图像内容进行调整。最后，这些经过加权的特征将与原始特征一起融合，以生成最终的多尺度语义对齐特征。

### 4.2 Loss Function
为了优化模型性能，文章采用了**深度监督策略**，即在每个解码器级别生成中间结果，并结合真实标签进行监督。同时，感知损失的引入帮助模型在修复过程中保持语义信息。

#### 损失函数设计
损失函数主要由两部分组成：
1. **像素级 \(L_1\) 损失**：用于衡量去摩尔纹图像与真实图像在像素级别的差异。\(L_1\)损失能够惩罚图像中的较大差异，有助于保持图像的整体结构。
2. **感知损失（Perceptual Loss）**：通过VGG16网络提取特征，在特征空间中计算图像与真实图像的差异，确保在去除摩尔纹的同时保留图像的细节和

语义信息。

深度监督策略和感知损失的结合，使得网络能够在多层次上精确去除摩尔纹，同时保持图像结构和语义的一致性。

---

## 5. Experiments

### 5.1 Comparisons with State-of-the-Art Methods
文章在**UHDM**数据集以及其他三个公开的去摩尔纹数据集上（FHDMi、TIP2018、LCD-Moiré）进行了实验，并通过PSNR、SSIM和LPIPS等图像质量评价指标对模型性能进行评估。

#### 定量比较
表2显示了ESDNet与现有最先进方法的定量性能对比。**ESDNet**在多个数据集上均表现出色，特别是在**UHDM**和**FHDMi**数据集上，PSNR值比FHDe²Net高出约1.8dB，并且推理速度快了近300倍。相比其他方法，ESDNet不仅具备更强的去摩尔纹能力，还保持了较低的计算成本，非常适合应用于4K图像的处理。

#### 定性比较
图5展示了ESDNet与其他方法的定性比较结果。与MDDM、DMCNN等方法相比，ESDNet能够更好地去除大尺度摩尔纹，并且在颜色和细节保留方面表现更为出色。FHDe²Net尽管在某些任务中表现优于其他方法，但存在严重的细节丢失问题，而ESDNet能够有效避免这一问题，进一步证明了其优越性。

### 5.2 Ablation Study
为了验证**SAM模块**的有效性，文章通过消融实验分别对模块中的金字塔特征提取和跨尺度动态融合进行实验分析。结果表明，SAM模块中的金字塔特征提取显著提升了模型的PSNR和LPIPS值，特别是在UHDM数据集上，模型性能得到了一致提升。此外，感知损失的引入进一步提升了去摩尔纹图像的视觉质量，尤其是在保留图像细节方面，表现尤为突出。

---

## 6. Conclusion
文章提出了一种轻量化且高效的去摩尔纹网络架构——**ESDNet**，并通过引入**语义对齐的多尺度感知模块（SAM）**，有效提升了网络在4K图像上的去摩尔纹能力。ESDNet不仅在UHDM数据集上表现出色，还在多个公开数据集上超越了现有的最先进方法。同时，文章构建了首个**超高清摩尔纹数据集UHDM**，为未来的研究提供了一个可靠的基准。

未来的研究可以进一步探索基于SAM的改进方法，提升去摩尔纹网络在真实世界应用中的泛化能力，特别是在资源受限的移动设备上实现更高效的摩尔纹处理。

---